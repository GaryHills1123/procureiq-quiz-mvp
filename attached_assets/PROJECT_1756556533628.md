# ProcureIQ Quiz MVP (Replit Project)

## Goal
Streamlit app on Replit that delivers **case-study quizzes** for procurement students.  
Each quiz = 1 scenario with 8–12 questions (system serves 10).  
End of quiz → **Radar Chart** across 6 core buyer competencies with **AI improvement suggestions**.  
MVP = **session-only, no persistence**.

## Locked Decisions
- Storage: one JSON file per case study in `/content/<slug>/quiz.json`
- Questions: 8–12 authored, 10 delivered per attempt
- Order: questions fixed, options fixed
- Feedback: end-only (summary + explanations)
- Multi-select wrong count: **reject & prompt**
- Helpers: stay on current question
- AI: always on (OpenAI key), broader procurement knowledge allowed, no answer leakage
- Results: radar + per-skill suggestions
- Runtime: Streamlit (Replit)

## Core Competencies (Radar Axes)
1. **Check the Facts** – verify claims with data/indices  
2. **Break Down the Costs** – dissect increases into components  
3. **Know the Market** – track trends & enforce fairness  
4. **Negotiate for Value** – trade price for terms/outcomes  
5. **Choose the Right Supplier Strategy** – segment suppliers & manage relationships  
6. **Learn and Improve** – capture lessons, ethics, continuous improvement  

## Replit Setup
- `.replit`: `run = "streamlit run app.py --server.port $PORT --server.address 0.0.0.0"`
- `requirements.txt`:
  - streamlit==1.37.1  
  - openai==1.40.6  
  - jsonschema>=4.22.0  
  - python-dotenv==1.0.1
- Secrets: `OPENAI_API_KEY`, (optional) `QUIZ_OPENAI_MODEL=gpt-4o-mini`

## Acceptance Criteria
- Quiz runs end-to-end with helpers
- Wrong multi-select count → prompts, not scored
- Radar chart rendered with 6 axes
- Improvement suggestions shown per competency
- Missed questions with explanations shown
